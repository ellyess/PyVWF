{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ab14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import vwf.data as vwf_data\n",
    "from calendar import monthrange\n",
    "def daysDuringMonth(yy, m):\n",
    "    \"\"\"\n",
    "    Attach number of days in month to each year in yy for month m.\n",
    "    \"\"\"\n",
    "    result = []    \n",
    "    [result.append(monthrange(y, m)[1]) for y in yy]        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1340ab08",
   "metadata": {},
   "source": [
    "# FRANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18232b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observed turbines/farms before conditions:  10276\n"
     ]
    }
   ],
   "source": [
    "fr_md = gpd.read_file(\"input/country-data/fr/fr_turb_info.csv\")\n",
    "fr_md = fr_md.loc[fr_md['statut_parc'] == 'Autorisé'].reset_index(drop=True)\n",
    "fr_md = fr_md.loc[\n",
    "    :, [\n",
    "    \"id_aerogenerateur\", \n",
    "    \"puissance_mw\", \n",
    "    \"diametre_rotor\",\n",
    "    \"hauteur_mat_nacelle\",\n",
    "\n",
    "    \"constructeur\",\n",
    "    \"x_aerogenerateur\",\n",
    "    \"y_aerogenerateur\",\n",
    "    \"epsg\"\n",
    "    ]]\n",
    "fr_md.columns = [\n",
    "    \"ID\",\n",
    "    \"capacity\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"manufacturer\",\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    \"epsg\"\n",
    "    ]\n",
    "\n",
    "points_gdf = gpd.GeoDataFrame(\n",
    "    fr_md[[\"ID\",\"capacity\",\"diameter\",\"height\",\"manufacturer\"]],\n",
    "    geometry=gpd.points_from_xy(fr_md.x, fr_md.y, crs=fr_md.epsg.iloc[0])\n",
    "    ).to_crs(epsg=4326)\n",
    "\n",
    "points_gdf['capacity'] = points_gdf['capacity'].astype(float) * 1e3  # MW to kW\n",
    "points_gdf['lon'] = points_gdf.geometry.x  \n",
    "points_gdf['lat'] = points_gdf.geometry.y\n",
    "points_gdf = points_gdf.drop(columns='geometry')\n",
    "\n",
    "# Convert to desired crs and save directly to a shapefile\n",
    "\n",
    "turb_info = vwf_data.add_models(points_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb1a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>obs_1</th>\n",
       "      <th>obs_2</th>\n",
       "      <th>obs_3</th>\n",
       "      <th>obs_4</th>\n",
       "      <th>obs_5</th>\n",
       "      <th>obs_6</th>\n",
       "      <th>obs_7</th>\n",
       "      <th>obs_8</th>\n",
       "      <th>obs_9</th>\n",
       "      <th>obs_10</th>\n",
       "      <th>obs_11</th>\n",
       "      <th>obs_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000044_E1</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.112989</td>\n",
       "      <td>0.103939</td>\n",
       "      <td>0.099125</td>\n",
       "      <td>0.073938</td>\n",
       "      <td>0.078874</td>\n",
       "      <td>0.064387</td>\n",
       "      <td>0.069476</td>\n",
       "      <td>0.055871</td>\n",
       "      <td>0.085045</td>\n",
       "      <td>0.063245</td>\n",
       "      <td>0.130545</td>\n",
       "      <td>0.131214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000000044_E1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.140924</td>\n",
       "      <td>0.152475</td>\n",
       "      <td>0.121089</td>\n",
       "      <td>0.085957</td>\n",
       "      <td>0.076693</td>\n",
       "      <td>0.054944</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.061687</td>\n",
       "      <td>0.050490</td>\n",
       "      <td>0.072020</td>\n",
       "      <td>0.123569</td>\n",
       "      <td>0.072072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000000044_E1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.099114</td>\n",
       "      <td>0.139221</td>\n",
       "      <td>0.130560</td>\n",
       "      <td>0.073974</td>\n",
       "      <td>0.072721</td>\n",
       "      <td>0.074893</td>\n",
       "      <td>0.084057</td>\n",
       "      <td>0.060763</td>\n",
       "      <td>0.083579</td>\n",
       "      <td>0.102415</td>\n",
       "      <td>0.116556</td>\n",
       "      <td>0.160125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000000044_E1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.196306</td>\n",
       "      <td>0.149803</td>\n",
       "      <td>0.151215</td>\n",
       "      <td>0.109189</td>\n",
       "      <td>0.077720</td>\n",
       "      <td>0.067985</td>\n",
       "      <td>0.052396</td>\n",
       "      <td>0.066873</td>\n",
       "      <td>0.079519</td>\n",
       "      <td>0.119011</td>\n",
       "      <td>0.137384</td>\n",
       "      <td>0.176818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000044_E2</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.112989</td>\n",
       "      <td>0.103939</td>\n",
       "      <td>0.099125</td>\n",
       "      <td>0.073938</td>\n",
       "      <td>0.078874</td>\n",
       "      <td>0.064387</td>\n",
       "      <td>0.069476</td>\n",
       "      <td>0.055871</td>\n",
       "      <td>0.085045</td>\n",
       "      <td>0.063245</td>\n",
       "      <td>0.130545</td>\n",
       "      <td>0.131214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40511</th>\n",
       "      <td>0100283090_E7</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.196306</td>\n",
       "      <td>0.149803</td>\n",
       "      <td>0.151215</td>\n",
       "      <td>0.109189</td>\n",
       "      <td>0.077720</td>\n",
       "      <td>0.067985</td>\n",
       "      <td>0.052396</td>\n",
       "      <td>0.066873</td>\n",
       "      <td>0.079519</td>\n",
       "      <td>0.119011</td>\n",
       "      <td>0.137384</td>\n",
       "      <td>0.176818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40512</th>\n",
       "      <td>0100283090_E8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.112989</td>\n",
       "      <td>0.103939</td>\n",
       "      <td>0.099125</td>\n",
       "      <td>0.073938</td>\n",
       "      <td>0.078874</td>\n",
       "      <td>0.064387</td>\n",
       "      <td>0.069476</td>\n",
       "      <td>0.055871</td>\n",
       "      <td>0.085045</td>\n",
       "      <td>0.063245</td>\n",
       "      <td>0.130545</td>\n",
       "      <td>0.131214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40513</th>\n",
       "      <td>0100283090_E8</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.140924</td>\n",
       "      <td>0.152475</td>\n",
       "      <td>0.121089</td>\n",
       "      <td>0.085957</td>\n",
       "      <td>0.076693</td>\n",
       "      <td>0.054944</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.061687</td>\n",
       "      <td>0.050490</td>\n",
       "      <td>0.072020</td>\n",
       "      <td>0.123569</td>\n",
       "      <td>0.072072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40514</th>\n",
       "      <td>0100283090_E8</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.099114</td>\n",
       "      <td>0.139221</td>\n",
       "      <td>0.130560</td>\n",
       "      <td>0.073974</td>\n",
       "      <td>0.072721</td>\n",
       "      <td>0.074893</td>\n",
       "      <td>0.084057</td>\n",
       "      <td>0.060763</td>\n",
       "      <td>0.083579</td>\n",
       "      <td>0.102415</td>\n",
       "      <td>0.116556</td>\n",
       "      <td>0.160125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40515</th>\n",
       "      <td>0100283090_E8</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.196306</td>\n",
       "      <td>0.149803</td>\n",
       "      <td>0.151215</td>\n",
       "      <td>0.109189</td>\n",
       "      <td>0.077720</td>\n",
       "      <td>0.067985</td>\n",
       "      <td>0.052396</td>\n",
       "      <td>0.066873</td>\n",
       "      <td>0.079519</td>\n",
       "      <td>0.119011</td>\n",
       "      <td>0.137384</td>\n",
       "      <td>0.176818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40516 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  year     obs_1     obs_2     obs_3     obs_4     obs_5  \\\n",
       "0      0000000044_E1  2015  0.112989  0.103939  0.099125  0.073938  0.078874   \n",
       "1      0000000044_E1  2016  0.140924  0.152475  0.121089  0.085957  0.076693   \n",
       "2      0000000044_E1  2017  0.099114  0.139221  0.130560  0.073974  0.072721   \n",
       "3      0000000044_E1  2018  0.196306  0.149803  0.151215  0.109189  0.077720   \n",
       "4      0000000044_E2  2015  0.112989  0.103939  0.099125  0.073938  0.078874   \n",
       "...              ...   ...       ...       ...       ...       ...       ...   \n",
       "40511  0100283090_E7  2018  0.196306  0.149803  0.151215  0.109189  0.077720   \n",
       "40512  0100283090_E8  2015  0.112989  0.103939  0.099125  0.073938  0.078874   \n",
       "40513  0100283090_E8  2016  0.140924  0.152475  0.121089  0.085957  0.076693   \n",
       "40514  0100283090_E8  2017  0.099114  0.139221  0.130560  0.073974  0.072721   \n",
       "40515  0100283090_E8  2018  0.196306  0.149803  0.151215  0.109189  0.077720   \n",
       "\n",
       "          obs_6     obs_7     obs_8     obs_9    obs_10    obs_11    obs_12  \n",
       "0      0.064387  0.069476  0.055871  0.085045  0.063245  0.130545  0.131214  \n",
       "1      0.054944  0.055716  0.061687  0.050490  0.072020  0.123569  0.072072  \n",
       "2      0.074893  0.084057  0.060763  0.083579  0.102415  0.116556  0.160125  \n",
       "3      0.067985  0.052396  0.066873  0.079519  0.119011  0.137384  0.176818  \n",
       "4      0.064387  0.069476  0.055871  0.085045  0.063245  0.130545  0.131214  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "40511  0.067985  0.052396  0.066873  0.079519  0.119011  0.137384  0.176818  \n",
       "40512  0.064387  0.069476  0.055871  0.085045  0.063245  0.130545  0.131214  \n",
       "40513  0.054944  0.055716  0.061687  0.050490  0.072020  0.123569  0.072072  \n",
       "40514  0.074893  0.084057  0.060763  0.083579  0.102415  0.116556  0.160125  \n",
       "40515  0.067985  0.052396  0.066873  0.079519  0.119011  0.137384  0.176818  \n",
       "\n",
       "[40516 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALTERNATIVE FR GENERATION DATA\n",
    "# https://ec.europa.eu/eurostat/databrowser/view/nrg_cb_pem__custom_19402431/default/table\n",
    "year_star = 2015 # start year of training period\n",
    "year_end = 2018\n",
    "ns_data = pd.read_csv(\"input/country-data/northsea_country_generation.csv\")\n",
    "ns_data = ns_data.loc[\n",
    "    :, [\n",
    "    \"Standard international energy product classification (SIEC)\", \n",
    "    \"TIME_PERIOD\", \n",
    "    \"OBS_VALUE\",\n",
    "    \"geo\",\n",
    "    ]]\n",
    "ns_data.columns = [\n",
    "    \"carrier\",\n",
    "    \"date\",\n",
    "    \"output\",\n",
    "    \"country\",\n",
    "    ]\n",
    "\n",
    "country = 'FR'  # Example country code\n",
    "ns_data = ns_data.loc[(ns_data['country']==country) & (ns_data['carrier']=='Wind')].reset_index(drop=True)\n",
    "ns_data['date'] = pd.to_datetime(ns_data['date'])\n",
    "# convert from gigawatt hours to kilowatt hours\n",
    "ns_data['output'] = pd.to_numeric(ns_data['output'])\n",
    "ns_data['output'] = ns_data['output'] * 1e6\n",
    "ns_data['year'] = ns_data['date'].dt.year.astype(int)\n",
    "ns_data['month'] = ns_data['date'].dt.month.astype(int)\n",
    "ns_data = ns_data.drop(columns=['date'])\n",
    "\n",
    "ns_data = ns_data.fillna(0).groupby(['year','month'])['output'].sum().reset_index()\n",
    "\n",
    "turb_info[\"ratio\"] = turb_info['capacity'] / turb_info['capacity'].sum()\n",
    "\n",
    "ns_data = ns_data.merge(turb_info[['ID', 'ratio']], how=\"cross\")\n",
    "ns_data[\"output\"] = ns_data[\"output\"] * ns_data[\"ratio\"]\n",
    "ns_data = ns_data.dropna(subset=['ID', 'year', 'month'])\n",
    "ns_data = ns_data.loc[(ns_data[\"year\"] >= year_star) & (ns_data[\"year\"] <= year_end)].reset_index(drop=True)   \n",
    "obs_gen = ns_data.pivot(index=['ID','year'], columns='month', values='output').reset_index()\n",
    "# obs_gen = ns_data.pivot(index=['type','year'], columns='month', values='output').reset_index()\n",
    "obs_gen.columns = [f'obs_{i}' if i not in ['ID', 'year'] else f'{i}' for i in obs_gen.columns]\n",
    "obs_gen = obs_gen.merge(turb_info[['ID', 'capacity']], how='left', on=['ID'])\n",
    "obs_gen = obs_gen.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,13):\n",
    "    obs_gen['obs_'+str(i)] = obs_gen['obs_'+str(i)]/(((daysDuringMonth(obs_gen.year, i))*obs_gen['capacity'])*24)\n",
    "\n",
    "obs_gen = obs_gen.drop(['capacity'], axis=1)\n",
    "obs_gen = obs_gen.sort_values(by=['ID','year']).reset_index(drop=True)\n",
    "obs_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e3833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42.50154105996311, 50.930297624283845, -4.757239614418522, 8.7060513884254)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turb_info.lat.min(), turb_info.lat.max(), turb_info.lon.min(), turb_info.lon.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70fbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>obs_1</th>\n",
       "      <th>obs_2</th>\n",
       "      <th>obs_3</th>\n",
       "      <th>obs_4</th>\n",
       "      <th>obs_5</th>\n",
       "      <th>obs_6</th>\n",
       "      <th>obs_7</th>\n",
       "      <th>obs_8</th>\n",
       "      <th>obs_9</th>\n",
       "      <th>obs_10</th>\n",
       "      <th>obs_11</th>\n",
       "      <th>obs_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000044_E1</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.119402</td>\n",
       "      <td>0.109819</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.077930</td>\n",
       "      <td>0.082066</td>\n",
       "      <td>0.067322</td>\n",
       "      <td>0.072649</td>\n",
       "      <td>0.058472</td>\n",
       "      <td>0.089848</td>\n",
       "      <td>0.067093</td>\n",
       "      <td>0.136548</td>\n",
       "      <td>0.133591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000000044_E1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.148005</td>\n",
       "      <td>0.160959</td>\n",
       "      <td>0.127405</td>\n",
       "      <td>0.089613</td>\n",
       "      <td>0.080062</td>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.052848</td>\n",
       "      <td>0.061672</td>\n",
       "      <td>0.053158</td>\n",
       "      <td>0.073204</td>\n",
       "      <td>0.124678</td>\n",
       "      <td>0.079410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000000044_E1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.106120</td>\n",
       "      <td>0.145694</td>\n",
       "      <td>0.137468</td>\n",
       "      <td>0.078337</td>\n",
       "      <td>0.077585</td>\n",
       "      <td>0.078801</td>\n",
       "      <td>0.088521</td>\n",
       "      <td>0.063991</td>\n",
       "      <td>0.087904</td>\n",
       "      <td>0.107737</td>\n",
       "      <td>0.124232</td>\n",
       "      <td>0.174759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000000044_E1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.207637</td>\n",
       "      <td>0.159707</td>\n",
       "      <td>0.162313</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.083022</td>\n",
       "      <td>0.073531</td>\n",
       "      <td>0.057142</td>\n",
       "      <td>0.072849</td>\n",
       "      <td>0.086501</td>\n",
       "      <td>0.129369</td>\n",
       "      <td>0.150310</td>\n",
       "      <td>0.189606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000044_E2</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.119402</td>\n",
       "      <td>0.109819</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.077930</td>\n",
       "      <td>0.082066</td>\n",
       "      <td>0.067322</td>\n",
       "      <td>0.072649</td>\n",
       "      <td>0.058472</td>\n",
       "      <td>0.089848</td>\n",
       "      <td>0.067093</td>\n",
       "      <td>0.136548</td>\n",
       "      <td>0.133591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40511</th>\n",
       "      <td>0100283090_E7</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.207637</td>\n",
       "      <td>0.159707</td>\n",
       "      <td>0.162313</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.083022</td>\n",
       "      <td>0.073531</td>\n",
       "      <td>0.057142</td>\n",
       "      <td>0.072849</td>\n",
       "      <td>0.086501</td>\n",
       "      <td>0.129369</td>\n",
       "      <td>0.150310</td>\n",
       "      <td>0.189606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40512</th>\n",
       "      <td>0100283090_E8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.119402</td>\n",
       "      <td>0.109819</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.077930</td>\n",
       "      <td>0.082066</td>\n",
       "      <td>0.067322</td>\n",
       "      <td>0.072649</td>\n",
       "      <td>0.058472</td>\n",
       "      <td>0.089848</td>\n",
       "      <td>0.067093</td>\n",
       "      <td>0.136548</td>\n",
       "      <td>0.133591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40513</th>\n",
       "      <td>0100283090_E8</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.148005</td>\n",
       "      <td>0.160959</td>\n",
       "      <td>0.127405</td>\n",
       "      <td>0.089613</td>\n",
       "      <td>0.080062</td>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.052848</td>\n",
       "      <td>0.061672</td>\n",
       "      <td>0.053158</td>\n",
       "      <td>0.073204</td>\n",
       "      <td>0.124678</td>\n",
       "      <td>0.079410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40514</th>\n",
       "      <td>0100283090_E8</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.106120</td>\n",
       "      <td>0.145694</td>\n",
       "      <td>0.137468</td>\n",
       "      <td>0.078337</td>\n",
       "      <td>0.077585</td>\n",
       "      <td>0.078801</td>\n",
       "      <td>0.088521</td>\n",
       "      <td>0.063991</td>\n",
       "      <td>0.087904</td>\n",
       "      <td>0.107737</td>\n",
       "      <td>0.124232</td>\n",
       "      <td>0.174759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40515</th>\n",
       "      <td>0100283090_E8</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.207637</td>\n",
       "      <td>0.159707</td>\n",
       "      <td>0.162313</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.083022</td>\n",
       "      <td>0.073531</td>\n",
       "      <td>0.057142</td>\n",
       "      <td>0.072849</td>\n",
       "      <td>0.086501</td>\n",
       "      <td>0.129369</td>\n",
       "      <td>0.150310</td>\n",
       "      <td>0.189606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40516 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  year     obs_1     obs_2     obs_3     obs_4     obs_5  \\\n",
       "0      0000000044_E1  2015  0.119402  0.109819  0.104127  0.077930  0.082066   \n",
       "1      0000000044_E1  2016  0.148005  0.160959  0.127405  0.089613  0.080062   \n",
       "2      0000000044_E1  2017  0.106120  0.145694  0.137468  0.078337  0.077585   \n",
       "3      0000000044_E1  2018  0.207637  0.159707  0.162313  0.115942  0.083022   \n",
       "4      0000000044_E2  2015  0.119402  0.109819  0.104127  0.077930  0.082066   \n",
       "...              ...   ...       ...       ...       ...       ...       ...   \n",
       "40511  0100283090_E7  2018  0.207637  0.159707  0.162313  0.115942  0.083022   \n",
       "40512  0100283090_E8  2015  0.119402  0.109819  0.104127  0.077930  0.082066   \n",
       "40513  0100283090_E8  2016  0.148005  0.160959  0.127405  0.089613  0.080062   \n",
       "40514  0100283090_E8  2017  0.106120  0.145694  0.137468  0.078337  0.077585   \n",
       "40515  0100283090_E8  2018  0.207637  0.159707  0.162313  0.115942  0.083022   \n",
       "\n",
       "          obs_6     obs_7     obs_8     obs_9    obs_10    obs_11    obs_12  \n",
       "0      0.067322  0.072649  0.058472  0.089848  0.067093  0.136548  0.133591  \n",
       "1      0.057473  0.052848  0.061672  0.053158  0.073204  0.124678  0.079410  \n",
       "2      0.078801  0.088521  0.063991  0.087904  0.107737  0.124232  0.174759  \n",
       "3      0.073531  0.057142  0.072849  0.086501  0.129369  0.150310  0.189606  \n",
       "4      0.067322  0.072649  0.058472  0.089848  0.067093  0.136548  0.133591  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "40511  0.073531  0.057142  0.072849  0.086501  0.129369  0.150310  0.189606  \n",
       "40512  0.067322  0.072649  0.058472  0.089848  0.067093  0.136548  0.133591  \n",
       "40513  0.057473  0.052848  0.061672  0.053158  0.073204  0.124678  0.079410  \n",
       "40514  0.078801  0.088521  0.063991  0.087904  0.107737  0.124232  0.174759  \n",
       "40515  0.073531  0.057142  0.072849  0.086501  0.129369  0.150310  0.189606  \n",
       "\n",
       "[40516 rows x 14 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_star = 2015 # start year of training period\n",
    "year_end = 2018 \n",
    "\n",
    "fr_data = pd.read_csv(\"input/country-data/FR/observations/Wind_power_generation_in_France.csv\")\n",
    "fr_data.columns = [\"date\", \"filter\", \"output\", \"nature\"]\n",
    "\n",
    "fr_data = fr_data.loc[fr_data['filter'].str.contains('evolution')].reset_index(drop=True)\n",
    "# fr_data[\"type\"] = fr_data[\"filter\"].str.split(\" \").str[0].str.lower()\n",
    "fr_data[\"output\"] = fr_data[\"output\"].replace(',', '.', regex=True)\n",
    "fr_data = fr_data.drop(columns=[\"nature\",\"filter\"])\n",
    "fr_data['date'] = pd.to_datetime(fr_data['date'])\n",
    "fr_data['output'] = pd.to_numeric(fr_data['output'])\n",
    "# convert from terawatts to kilowatts\n",
    "fr_data['output'] = fr_data['output'] * 1e9\n",
    "fr_data['year'] = fr_data['date'].dt.year.astype(int)\n",
    "fr_data['month'] = fr_data['date'].dt.month.astype(int)\n",
    "fr_data = fr_data.drop(columns=['date'])\n",
    "\n",
    "fr_data = fr_data.fillna(0).groupby(['year','month'])['output'].sum().reset_index()\n",
    "# fr_data['type'] = 'onshore'\n",
    "\n",
    "turb_info[\"ratio\"] = turb_info['capacity'] / turb_info['capacity'].sum()\n",
    "\n",
    "fr_data = fr_data.merge(turb_info[['ID', 'ratio']], how=\"cross\")\n",
    "fr_data[\"output\"] = fr_data[\"output\"] * fr_data[\"ratio\"]\n",
    "fr_data = fr_data.dropna(subset=['ID', 'year', 'month'])\n",
    "fr_data = fr_data.loc[(fr_data[\"year\"] >= year_star) & (fr_data[\"year\"] <= year_end)].reset_index(drop=True)   \n",
    "obs_gen = fr_data.pivot(index=['ID','year'], columns='month', values='output').reset_index()\n",
    "# obs_gen = fr_data.pivot(index=['type','year'], columns='month', values='output').reset_index()\n",
    "\n",
    "obs_gen.columns = [f'obs_{i}' if i not in ['ID', 'year'] else f'{i}' for i in obs_gen.columns]\n",
    "obs_gen = obs_gen.merge(turb_info[['ID', 'capacity']], how='left', on=['ID'])\n",
    "obs_gen = obs_gen.dropna().reset_index(drop=True)\n",
    "\n",
    "for i in range(1,13):\n",
    "    obs_gen['obs_'+str(i)] = obs_gen['obs_'+str(i)]/(((daysDuringMonth(obs_gen.year, i))*obs_gen['capacity'])*24)\n",
    "\n",
    "\n",
    "obs_gen = obs_gen.drop(['capacity'], axis=1)\n",
    "obs_gen = obs_gen.sort_values(by=['ID','year']).reset_index(drop=True)\n",
    "obs_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdcd3c6",
   "metadata": {},
   "source": [
    "# NETHERLANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c08d9d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "input/country-data/NL/nl_md.json: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDataSourceError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# https://nationaalgeoregister.nl/geonetwork/srv/dut/catalog.search#/metadata/90f5eab6-9cea-4869-a031-2a228fb82fea\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m nl_md = \u001b[43mgpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput/country-data/NL/nl_md.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.to_crs(epsg=\u001b[32m4326\u001b[39m)\n\u001b[32m      3\u001b[39m nl_md[\u001b[33m'\u001b[39m\u001b[33mlon\u001b[39m\u001b[33m'\u001b[39m] = nl_md.geometry.x  \n\u001b[32m      4\u001b[39m nl_md[\u001b[33m'\u001b[39m\u001b[33mlat\u001b[39m\u001b[33m'\u001b[39m] = nl_md.geometry.y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pyvwf/lib/python3.12/site-packages/geopandas/io/file.py:316\u001b[39m, in \u001b[36m_read_file\u001b[39m\u001b[34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[39m\n\u001b[32m    313\u001b[39m             filename = response.read()\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyogrio\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mfiona\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.api.types.is_file_like(filename):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pyvwf/lib/python3.12/site-packages/geopandas/io/file.py:576\u001b[39m, in \u001b[36m_read_file_pyogrio\u001b[39m\u001b[34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m     warnings.warn(\n\u001b[32m    568\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33minclude_fields\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mignore_fields\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keywords are deprecated, and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    569\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future release. You can use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keyword \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    572\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    573\u001b[39m     )\n\u001b[32m    574\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33minclude_fields\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pyvwf/lib/python3.12/site-packages/pyogrio/geopandas.py:275\u001b[39m, in \u001b[36mread_dataframe\u001b[39m\u001b[34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[32m    272\u001b[39m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[32m    274\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdatetime_as_string\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m result = \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpa\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pyvwf/lib/python3.12/site-packages/pyogrio/raw.py:198\u001b[39m, in \u001b[36mread\u001b[39m\u001b[34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m dataset_kwargs = _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:1313\u001b[39m, in \u001b[36mpyogrio._io.ogr_read\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:232\u001b[39m, in \u001b[36mpyogrio._io.ogr_open\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mDataSourceError\u001b[39m: input/country-data/NL/nl_md.json: No such file or directory"
     ]
    }
   ],
   "source": [
    "# https://nationaalgeoregister.nl/geonetwork/srv/dut/catalog.search#/metadata/90f5eab6-9cea-4869-a031-2a228fb82fea\n",
    "nl_md = gpd.read_file(\"input/country-data/NL/nl_md.json\").to_crs(epsg=4326)\n",
    "nl_md['lon'] = nl_md.geometry.x  \n",
    "nl_md['lat'] = nl_md.geometry.y\n",
    "nl_md = nl_md.drop(columns=['geometry','x','y','prov_naam','gem_naam','naam'])\n",
    "nl_md[\"ondergrond\"] = nl_md[\"ondergrond\"].replace({\"land\": \"onshore\", \"zee\": \"offshore\"})\n",
    "nl_md[\"land\"] = nl_md[\"land\"].replace({\"België\": \"BE\", \"Duitsland\": \"DE\", \"Nederland\": \"NL\"})\n",
    "nl_md.columns = [\n",
    "    \"ID\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"capacity\",\n",
    "    \"country\",\n",
    "    \"manufacturer\",\n",
    "    \"type\",\n",
    "    \"lon\",\n",
    "    \"lat\"\n",
    "]\n",
    "nl_md\n",
    "# nl_md = nl_md.loc[nl_md['country']=='NL'].reset_index(drop=True).drop(columns=['country'])\n",
    "# nl_md = nl_md[[\"ID\",\"capacity\",\"diameter\",\"height\",\"manufacturer\",\"lon\",\"lat\",\"type\"]]\n",
    "# nl_md['manufacturer'] = nl_md['manufacturer'].str.split(' ').str[0].str.strip('123-.,').astype(str)\n",
    "# turb_info = vwf_data.add_models(nl_md)\n",
    "# turb_info\n",
    "# nl_md['manufacturer'].str.strip().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb61ef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m year_star = \u001b[32m2015\u001b[39m \u001b[38;5;66;03m# start year of training period\u001b[39;00m\n\u001b[32m      3\u001b[39m year_end = \u001b[32m2018\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ns_data = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m\"\u001b[39m\u001b[33minput/country-data/northsea_country_generation.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m ns_data = ns_data.loc[\n\u001b[32m      6\u001b[39m     :, [\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mStandard international energy product classification (SIEC)\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgeo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     ]]\n\u001b[32m     12\u001b[39m ns_data.columns = [\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcarrier\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     ]\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# https://ec.europa.eu/eurostat/databrowser/view/nrg_cb_pem__custom_19402431/default/table\n",
    "year_star = 2015 # start year of training period\n",
    "year_end = 2018\n",
    "ns_data = pd.read_csv(\"input/country-data/northsea_country_generation.csv\")\n",
    "ns_data = ns_data.loc[\n",
    "    :, [\n",
    "    \"Standard international energy product classification (SIEC)\", \n",
    "    \"TIME_PERIOD\", \n",
    "    \"OBS_VALUE\",\n",
    "    \"geo\",\n",
    "    ]]\n",
    "ns_data.columns = [\n",
    "    \"carrier\",\n",
    "    \"date\",\n",
    "    \"output\",\n",
    "    \"country\",\n",
    "    ]\n",
    "\n",
    "country = 'NL'  # Example country code\n",
    "ns_data = ns_data.loc[(ns_data['country']==country) & (ns_data['carrier']=='Wind')].reset_index(drop=True)\n",
    "ns_data['date'] = pd.to_datetime(ns_data['date'])\n",
    "# convert from gigawatt hours to kilowatt hours\n",
    "ns_data['output'] = pd.to_numeric(ns_data['output'])\n",
    "ns_data['output'] = ns_data['output'] * 1e6\n",
    "ns_data['year'] = ns_data['date'].dt.year.astype(int)\n",
    "ns_data['month'] = ns_data['date'].dt.month.astype(int)\n",
    "ns_data = ns_data.drop(columns=['date'])\n",
    "\n",
    "ns_data = ns_data.fillna(0).groupby(['year','month'])['output'].sum().reset_index()\n",
    "\n",
    "turb_info[\"ratio\"] = turb_info['capacity'] / turb_info['capacity'].sum()\n",
    "\n",
    "ns_data = ns_data.merge(turb_info[['ID', 'ratio']], how=\"cross\")\n",
    "ns_data[\"output\"] = ns_data[\"output\"] * ns_data[\"ratio\"]\n",
    "ns_data = ns_data.dropna(subset=['ID', 'year', 'month'])\n",
    "ns_data = ns_data.loc[(ns_data[\"year\"] >= year_star) & (ns_data[\"year\"] <= year_end)].reset_index(drop=True)   \n",
    "obs_gen = ns_data.pivot(index=['ID','year'], columns='month', values='output').reset_index()\n",
    "# obs_gen = ns_data.pivot(index=['type','year'], columns='month', values='output').reset_index()\n",
    "obs_gen.columns = [f'obs_{i}' if i not in ['ID', 'year'] else f'{i}' for i in obs_gen.columns]\n",
    "obs_gen = obs_gen.merge(turb_info[['ID', 'capacity']], how='left', on=['ID'])\n",
    "obs_gen = obs_gen.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,13):\n",
    "    obs_gen['obs_'+str(i)] = obs_gen['obs_'+str(i)]/(((daysDuringMonth(obs_gen.year, i))*obs_gen['capacity'])*24)\n",
    "\n",
    "obs_gen = obs_gen.drop(['capacity'], axis=1)\n",
    "obs_gen = obs_gen.sort_values(by=['ID','year']).reset_index(drop=True)\n",
    "obs_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45aba625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BE', 'FR', 'NL', 'NO'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_star = 2015 # start year of training period\n",
    "year_end = 2018\n",
    "ns_data = pd.read_csv(\"../input/country-data/northsea_country_generation.csv\")\n",
    "ns_data = ns_data.loc[\n",
    "    :, [\n",
    "    \"Standard international energy product classification (SIEC)\", \n",
    "    \"TIME_PERIOD\", \n",
    "    \"OBS_VALUE\",\n",
    "    \"geo\",\n",
    "    ]]\n",
    "ns_data.columns = [\n",
    "    \"carrier\",\n",
    "    \"date\",\n",
    "    \"output\",\n",
    "    \"country\",\n",
    "    ]\n",
    "ns_data.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d86be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.84785605236023, 54.073136499178204, 2.774671661010408, 7.1778683054236145)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turb_info.lat.min(), turb_info.lat.max(), turb_info.lon.min(), turb_info.lon.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f8922dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th>cet_cest_timestamp</th>\n",
       "      <th>BE_wind_generation_actual</th>\n",
       "      <th>BE_wind_offshore_generation_actual</th>\n",
       "      <th>BE_wind_onshore_generation_actual</th>\n",
       "      <th>FR_wind_onshore_generation_actual</th>\n",
       "      <th>NL_wind_generation_actual</th>\n",
       "      <th>NL_wind_offshore_generation_actual</th>\n",
       "      <th>NL_wind_onshore_generation_actual</th>\n",
       "      <th>NO_wind_onshore_generation_actual</th>\n",
       "      <th>NO_1_wind_onshore_generation_actual</th>\n",
       "      <th>NO_2_wind_onshore_generation_actual</th>\n",
       "      <th>NO_3_wind_onshore_generation_actual</th>\n",
       "      <th>NO_4_wind_onshore_generation_actual</th>\n",
       "      <th>NO_5_wind_onshore_generation_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31T23:00:00Z</td>\n",
       "      <td>2015-01-01T00:00:00+0100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01T00:00:00Z</td>\n",
       "      <td>2015-01-01T01:00:00+0100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01T01:00:00Z</td>\n",
       "      <td>2015-01-01T02:00:00+0100</td>\n",
       "      <td>734.81</td>\n",
       "      <td>518.66</td>\n",
       "      <td>216.15</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>479.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.60</td>\n",
       "      <td>233.53</td>\n",
       "      <td>68.67</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01T02:00:00Z</td>\n",
       "      <td>2015-01-01T03:00:00+0100</td>\n",
       "      <td>766.64</td>\n",
       "      <td>529.46</td>\n",
       "      <td>237.18</td>\n",
       "      <td>1543.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>422.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.20</td>\n",
       "      <td>200.27</td>\n",
       "      <td>54.67</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01T03:00:00Z</td>\n",
       "      <td>2015-01-01T04:00:00+0100</td>\n",
       "      <td>733.13</td>\n",
       "      <td>406.94</td>\n",
       "      <td>326.19</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>408.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.50</td>\n",
       "      <td>192.22</td>\n",
       "      <td>54.03</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50396</th>\n",
       "      <td>2020-09-30T19:00:00Z</td>\n",
       "      <td>2020-09-30T21:00:00+0200</td>\n",
       "      <td>1889.72</td>\n",
       "      <td>1497.40</td>\n",
       "      <td>392.32</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>1533.20</td>\n",
       "      <td>94.20</td>\n",
       "      <td>964.93</td>\n",
       "      <td>376.02</td>\n",
       "      <td>98.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50397</th>\n",
       "      <td>2020-09-30T20:00:00Z</td>\n",
       "      <td>2020-09-30T22:00:00+0200</td>\n",
       "      <td>2154.67</td>\n",
       "      <td>1688.06</td>\n",
       "      <td>466.61</td>\n",
       "      <td>3965.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>1645.93</td>\n",
       "      <td>86.20</td>\n",
       "      <td>1034.32</td>\n",
       "      <td>425.09</td>\n",
       "      <td>100.32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50398</th>\n",
       "      <td>2020-09-30T21:00:00Z</td>\n",
       "      <td>2020-09-30T23:00:00+0200</td>\n",
       "      <td>2187.48</td>\n",
       "      <td>1715.76</td>\n",
       "      <td>471.72</td>\n",
       "      <td>4201.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1635.35</td>\n",
       "      <td>80.69</td>\n",
       "      <td>1008.48</td>\n",
       "      <td>436.27</td>\n",
       "      <td>109.91</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50399</th>\n",
       "      <td>2020-09-30T22:00:00Z</td>\n",
       "      <td>2020-10-01T00:00:00+0200</td>\n",
       "      <td>2225.62</td>\n",
       "      <td>1739.17</td>\n",
       "      <td>486.45</td>\n",
       "      <td>4428.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1698.59</td>\n",
       "      <td>84.76</td>\n",
       "      <td>1003.72</td>\n",
       "      <td>505.29</td>\n",
       "      <td>104.82</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50400</th>\n",
       "      <td>2020-09-30T23:00:00Z</td>\n",
       "      <td>2020-10-01T01:00:00+0200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>959.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50401 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              utc_timestamp        cet_cest_timestamp  \\\n",
       "0      2014-12-31T23:00:00Z  2015-01-01T00:00:00+0100   \n",
       "1      2015-01-01T00:00:00Z  2015-01-01T01:00:00+0100   \n",
       "2      2015-01-01T01:00:00Z  2015-01-01T02:00:00+0100   \n",
       "3      2015-01-01T02:00:00Z  2015-01-01T03:00:00+0100   \n",
       "4      2015-01-01T03:00:00Z  2015-01-01T04:00:00+0100   \n",
       "...                     ...                       ...   \n",
       "50396  2020-09-30T19:00:00Z  2020-09-30T21:00:00+0200   \n",
       "50397  2020-09-30T20:00:00Z  2020-09-30T22:00:00+0200   \n",
       "50398  2020-09-30T21:00:00Z  2020-09-30T23:00:00+0200   \n",
       "50399  2020-09-30T22:00:00Z  2020-10-01T00:00:00+0200   \n",
       "50400  2020-09-30T23:00:00Z  2020-10-01T01:00:00+0200   \n",
       "\n",
       "       BE_wind_generation_actual  BE_wind_offshore_generation_actual  \\\n",
       "0                            NaN                                 NaN   \n",
       "1                            NaN                                 NaN   \n",
       "2                         734.81                              518.66   \n",
       "3                         766.64                              529.46   \n",
       "4                         733.13                              406.94   \n",
       "...                          ...                                 ...   \n",
       "50396                    1889.72                             1497.40   \n",
       "50397                    2154.67                             1688.06   \n",
       "50398                    2187.48                             1715.76   \n",
       "50399                    2225.62                             1739.17   \n",
       "50400                        NaN                                 NaN   \n",
       "\n",
       "       BE_wind_onshore_generation_actual  FR_wind_onshore_generation_actual  \\\n",
       "0                                    NaN                                NaN   \n",
       "1                                    NaN                                NaN   \n",
       "2                                 216.15                             1464.0   \n",
       "3                                 237.18                             1543.0   \n",
       "4                                 326.19                             1579.0   \n",
       "...                                  ...                                ...   \n",
       "50396                             392.32                             3632.0   \n",
       "50397                             466.61                             3965.0   \n",
       "50398                             471.72                             4201.0   \n",
       "50399                             486.45                             4428.0   \n",
       "50400                                NaN                                NaN   \n",
       "\n",
       "       NL_wind_generation_actual  NL_wind_offshore_generation_actual  \\\n",
       "0                            NaN                                 NaN   \n",
       "1                         1451.0                               145.0   \n",
       "2                         1447.0                               145.0   \n",
       "3                         1479.0                               148.0   \n",
       "4                         1340.0                               134.0   \n",
       "...                          ...                                 ...   \n",
       "50396                      870.0                               589.0   \n",
       "50397                      978.0                               650.0   \n",
       "50398                      988.0                               705.0   \n",
       "50399                      912.0                               662.0   \n",
       "50400                      959.0                               704.0   \n",
       "\n",
       "       NL_wind_onshore_generation_actual  NO_wind_onshore_generation_actual  \\\n",
       "0                                    NaN                                NaN   \n",
       "1                                 1306.0                                NaN   \n",
       "2                                 1302.0                             479.40   \n",
       "3                                 1331.0                             422.74   \n",
       "4                                 1206.0                             408.35   \n",
       "...                                  ...                                ...   \n",
       "50396                              281.0                            1533.20   \n",
       "50397                              328.0                            1645.93   \n",
       "50398                              284.0                            1635.35   \n",
       "50399                              250.0                            1698.59   \n",
       "50400                              256.0                                NaN   \n",
       "\n",
       "       NO_1_wind_onshore_generation_actual  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "...                                    ...   \n",
       "50396                                94.20   \n",
       "50397                                86.20   \n",
       "50398                                80.69   \n",
       "50399                                84.76   \n",
       "50400                                  NaN   \n",
       "\n",
       "       NO_2_wind_onshore_generation_actual  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                   158.60   \n",
       "3                                   149.20   \n",
       "4                                   143.50   \n",
       "...                                    ...   \n",
       "50396                               964.93   \n",
       "50397                              1034.32   \n",
       "50398                              1008.48   \n",
       "50399                              1003.72   \n",
       "50400                                  NaN   \n",
       "\n",
       "       NO_3_wind_onshore_generation_actual  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                   233.53   \n",
       "3                                   200.27   \n",
       "4                                   192.22   \n",
       "...                                    ...   \n",
       "50396                               376.02   \n",
       "50397                               425.09   \n",
       "50398                               436.27   \n",
       "50399                               505.29   \n",
       "50400                                  NaN   \n",
       "\n",
       "       NO_4_wind_onshore_generation_actual  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                    68.67   \n",
       "3                                    54.67   \n",
       "4                                    54.03   \n",
       "...                                    ...   \n",
       "50396                                98.05   \n",
       "50397                               100.32   \n",
       "50398                               109.91   \n",
       "50399                               104.82   \n",
       "50400                                  NaN   \n",
       "\n",
       "       NO_5_wind_onshore_generation_actual  \n",
       "0                                      NaN  \n",
       "1                                      NaN  \n",
       "2                                     18.6  \n",
       "3                                     18.6  \n",
       "4                                     18.6  \n",
       "...                                    ...  \n",
       "50396                                  NaN  \n",
       "50397                                  NaN  \n",
       "50398                                  NaN  \n",
       "50399                                  NaN  \n",
       "50400                                  NaN  \n",
       "\n",
       "[50401 rows x 15 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://data.open-power-system-data.org/time_series.com\n",
    "data = pd.read_csv(\"input/country-data/time_series_60min_singleindex_filtered.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862542a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57914004",
   "metadata": {},
   "source": [
    "# DATA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fcad79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote NO_wind_metadata_pseudoturbines.csv\n",
      "Rows: 1427\n",
      "Missing lon/lat: 1427 1427\n",
      "Missing capacity: 0\n",
      "Missing diameter: 1427\n",
      "Missing height: 1427\n",
      "Manufacturer non-null: 0\n",
      "                ID  capacity  diameter  height manufacturer  lon  lat     type\n",
      "0  NO_20_blk_0_t_0       2.3       NaN     NaN         None  NaN  NaN  onshore\n",
      "1  NO_20_blk_0_t_1       2.3       NaN     NaN         None  NaN  NaN  onshore\n",
      "2  NO_20_blk_0_t_2       2.3       NaN     NaN         None  NaN  NaN  onshore\n",
      "3  NO_20_blk_0_t_3       2.3       NaN     NaN         None  NaN  NaN  onshore\n",
      "4  NO_20_blk_0_t_4       2.3       NaN     NaN         None  NaN  NaN  onshore\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Norway wind metadata from NVE (operational plants) -> pseudo-turbines.\n",
    "\n",
    "Outputs CSV with columns:\n",
    "[\"ID\",\"capacity\",\"diameter\",\"height\",\"manufacturer\",\"lon\",\"lat\",\"type\"]\n",
    "\n",
    "Key idea:\n",
    "- NVE returns plant-level records, often with \"Turbiner\" blocks.\n",
    "- Each block typically has AntallTurbiner (count) and TurbinStorrelse_kW (per-turbine size).\n",
    "- We expand each block into N pseudo-turbine rows at the plant centroid (same lon/lat).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "SCHEMA = [\"ID\", \"capacity\", \"diameter\", \"height\", \"manufacturer\", \"lon\", \"lat\", \"type\"]\n",
    "\n",
    "NVE_ENDPOINT = \"https://api.nve.no/web/WindPowerplant/GetWindPowerPlantsInOperation\"\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def _first(d: dict, keys: list[str], default=None):\n",
    "    for k in keys:\n",
    "        if k in d and d[k] not in (None, \"\", \"null\"):\n",
    "            return d[k]\n",
    "    return default\n",
    "\n",
    "\n",
    "def _to_float(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, (int, float)):\n",
    "        return float(x)\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    m = re.search(r\"[-+]?\\d*\\.?\\d+\", s.replace(\",\", \".\"))\n",
    "    return float(m.group(0)) if m else None\n",
    "\n",
    "\n",
    "def _to_int(x):\n",
    "    f = _to_float(x)\n",
    "    if f is None or math.isnan(f):\n",
    "        return None\n",
    "    return int(round(f))\n",
    "\n",
    "\n",
    "def fetch_nve_in_operation(retries: int = 3, timeout: int = 60) -> list[dict]:\n",
    "    last_err = None\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            r = requests.get(NVE_ENDPOINT, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if not isinstance(data, list):\n",
    "                raise ValueError(f\"Unexpected JSON root type: {type(data)}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(2 + i * 2)\n",
    "    raise last_err\n",
    "\n",
    "\n",
    "def _get_lon_lat(plant: dict) -> tuple[float | None, float | None]:\n",
    "    # NVE field names can vary; try a few common ones\n",
    "    lon = _first(plant, [\"Longitude\", \"lon\", \"Long\", \"X\", \"x\", \"x_coord\", \"x_coordinaat\"])\n",
    "    lat = _first(plant, [\"Latitude\", \"lat\", \"Lat\", \"Y\", \"y\", \"y_coord\", \"y_coordinaat\"])\n",
    "    return _to_float(lon), _to_float(lat)\n",
    "\n",
    "\n",
    "def _get_plant_id(plant: dict) -> str:\n",
    "    pid = _first(plant, [\"VindkraftAnleggId\", \"anleggId\", \"id\", \"ID\"])\n",
    "    return str(pid) if pid is not None else \"unknown\"\n",
    "\n",
    "\n",
    "def _guess_block_diameter(block: dict) -> float | None:\n",
    "    # try a few plausible keys\n",
    "    return _to_float(_first(block, [\"RotorDiameter\", \"rotor_diameter\", \"rotordiameter\", \"Rotor_diameter\"]))\n",
    "\n",
    "\n",
    "def _guess_block_hub_height(block: dict) -> float | None:\n",
    "    return _to_float(_first(block, [\"NavHoyde\", \"HubHeight\", \"hub_height\", \"ashoogte\", \"Hub_height\"]))\n",
    "\n",
    "\n",
    "def _guess_block_manufacturer(block: dict) -> str | None:\n",
    "    m = _first(block, [\"Produsent\", \"Manufacturer\", \"manufacturer\", \"Maker\", \"maker\", \"brand\"])\n",
    "    if m is None:\n",
    "        return None\n",
    "    s = str(m).strip()\n",
    "    return s if s else None\n",
    "\n",
    "\n",
    "def _guess_block_count(block: dict) -> int | None:\n",
    "    return _to_int(_first(block, [\"AntallTurbiner\", \"count\", \"Count\", \"number\", \"Number\"]))\n",
    "\n",
    "\n",
    "def _guess_block_size_kw(block: dict) -> float | None:\n",
    "    # per-turbine size in kW is often here\n",
    "    return _to_float(_first(block, [\"TurbinStorrelse_kW\", \"Size_kW\", \"size_kw\", \"kW\"]))\n",
    "\n",
    "\n",
    "def _guess_plant_installed_mw(plant: dict) -> float | None:\n",
    "    return _to_float(_first(plant, [\"InstallertEffekt_MW\", \"installed_mw\", \"InstalledMW\", \"capacity_mw\"]))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main transformation\n",
    "# -------------------------\n",
    "def nve_to_pseudoturbines(\n",
    "    data: list[dict],\n",
    "    *,\n",
    "    expand: bool = True,\n",
    "    fallback_single_if_missing_count: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert NVE JSON to pseudo-turbine dataframe.\n",
    "\n",
    "    - If expand=True:\n",
    "        For each plant turbine block with count N, create N rows.\n",
    "        Each row has per-turbine capacity (MW) from (TurbinStorrelse_kW / 1000).\n",
    "        Diameter/height/manufacturer copied from block if present.\n",
    "        Coordinates are plant centroid.\n",
    "\n",
    "    - If a plant has no Turbiner blocks:\n",
    "        Create one row at plant level (capacity from InstallertEffekt_MW).\n",
    "    \"\"\"\n",
    "    rows: list[dict] = []\n",
    "\n",
    "    for plant in data:\n",
    "        pid = _get_plant_id(plant)\n",
    "        lon, lat = _get_lon_lat(plant)\n",
    "\n",
    "        # Some records may not have coordinates; keep them (but they may be dropped later)\n",
    "        # You can choose to skip, but keeping is safer for debugging.\n",
    "        plant_installed_mw = _guess_plant_installed_mw(plant)\n",
    "\n",
    "        blocks = plant.get(\"Turbiner\") or []\n",
    "\n",
    "        if isinstance(blocks, list) and blocks and expand:\n",
    "            for b_i, block in enumerate(blocks):\n",
    "                n = _guess_block_count(block)\n",
    "                size_kw = _guess_block_size_kw(block)\n",
    "                diameter = _guess_block_diameter(block)\n",
    "                hub_height = _guess_block_hub_height(block)\n",
    "                manufacturer = _guess_block_manufacturer(block)\n",
    "\n",
    "                # per-turbine capacity in MW if size_kw present\n",
    "                cap_per_turb_mw = (size_kw / 1000.0) if size_kw is not None else None\n",
    "\n",
    "                if n is None or n <= 0:\n",
    "                    if fallback_single_if_missing_count:\n",
    "                        # One pseudo-turbine row for the whole block\n",
    "                        rows.append(\n",
    "                            {\n",
    "                                \"ID\": f\"NO_{pid}_blk_{b_i}_t_0\",\n",
    "                                \"capacity\": cap_per_turb_mw,  # may be None\n",
    "                                \"diameter\": diameter,\n",
    "                                \"height\": hub_height,\n",
    "                                \"manufacturer\": manufacturer,\n",
    "                                \"lon\": lon,\n",
    "                                \"lat\": lat,\n",
    "                                \"type\": \"onshore\",\n",
    "                            }\n",
    "                        )\n",
    "                    continue\n",
    "\n",
    "                for t_i in range(n):\n",
    "                    rows.append(\n",
    "                        {\n",
    "                            \"ID\": f\"NO_{pid}_blk_{b_i}_t_{t_i}\",\n",
    "                            \"capacity\": cap_per_turb_mw,  # MW per pseudo-turbine\n",
    "                            \"diameter\": diameter,\n",
    "                            \"height\": hub_height,\n",
    "                            \"manufacturer\": manufacturer,\n",
    "                            \"lon\": lon,\n",
    "                            \"lat\": lat,\n",
    "                            \"type\": \"onshore\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        else:\n",
    "            # Plant-level fallback (no blocks)\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"ID\": f\"NO_{pid}_plant\",\n",
    "                    \"capacity\": plant_installed_mw,  # MW (plant total)\n",
    "                    \"diameter\": None,\n",
    "                    \"height\": None,\n",
    "                    \"manufacturer\": None,\n",
    "                    \"lon\": lon,\n",
    "                    \"lat\": lat,\n",
    "                    \"type\": \"onshore\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(rows).reindex(columns=SCHEMA)\n",
    "\n",
    "    # Make sure numeric cols are numeric\n",
    "    for c in [\"capacity\", \"diameter\", \"height\", \"lon\", \"lat\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def sanity_report(df: pd.DataFrame) -> None:\n",
    "    print(\"Rows:\", len(df))\n",
    "    print(\"Missing lon/lat:\", int(df[\"lon\"].isna().sum()), int(df[\"lat\"].isna().sum()))\n",
    "    print(\"Missing capacity:\", int(df[\"capacity\"].isna().sum()))\n",
    "    print(\"Missing diameter:\", int(df[\"diameter\"].isna().sum()))\n",
    "    print(\"Missing height:\", int(df[\"height\"].isna().sum()))\n",
    "    print(\"Manufacturer non-null:\", int(df[\"manufacturer\"].notna().sum()))\n",
    "    print(df.head(5))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CLI / Run\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    out_csv = \"NO_wind_metadata_pseudoturbines.csv\"  # always write here\n",
    "\n",
    "    data = fetch_nve_in_operation()\n",
    "    df = nve_to_pseudoturbines(data, expand=True)\n",
    "\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"Wrote {out_csv}\")\n",
    "    sanity_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3bfb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote NO_wind_metadata_pseudoturbines.csv\n",
      "rows: 1427\n",
      "missing lon: 10\n",
      "missing lat: 10\n",
      "missing diameter: 0\n",
      "missing height: 0\n",
      "                ID  capacity  diameter  height manufacturer        lon  \\\n",
      "0  NO_20_blk_0_t_0       2.3      71.0    64.0      Enercon  10.374618   \n",
      "1  NO_20_blk_0_t_1       2.3      71.0    64.0      Enercon  10.374618   \n",
      "2  NO_20_blk_0_t_2       2.3      71.0    64.0      Enercon  10.374618   \n",
      "3  NO_20_blk_0_t_3       2.3      71.0    64.0      Enercon  10.374618   \n",
      "4  NO_20_blk_0_t_4       2.3      71.0    64.0      Enercon  10.374618   \n",
      "\n",
      "         lat     type  \n",
      "0  64.224811  onshore  \n",
      "1  64.224811  onshore  \n",
      "2  64.224811  onshore  \n",
      "3  64.224811  onshore  \n",
      "4  64.224811  onshore  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NORWAY wind pseudo-turbines (onshore) from:\n",
    "1) NVE WindPowerplant API (blocks: AntallTurbiner, TurbinStorrelse_kW, TurbinProdusent)\n",
    "2) rebase-energy/nve-windpower-data CSV (coords + AvgHubHeight + AvgRotorDiameter)\n",
    "\n",
    "Output columns:\n",
    "[\"ID\",\"capacity\",\"diameter\",\"height\",\"manufacturer\",\"lon\",\"lat\",\"type\"]\n",
    "\n",
    "No 'datasets' / pyarrow required.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import io\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "SCHEMA = [\"ID\", \"capacity\", \"diameter\", \"height\", \"manufacturer\", \"lon\", \"lat\", \"type\"]\n",
    "\n",
    "# NVE (operational plants)\n",
    "NVE_IN_OPERATION = \"https://api.nve.no/web/WindPowerplant/GetWindPowerPlantsInOperation\"\n",
    "\n",
    "# Rebase-energy dataset (direct raw CSV on GitHub-backed HuggingFace repo)\n",
    "# This file contains plant-level metadata including coordinates and averages.\n",
    "# If the filename ever changes upstream, check the repo file list.\n",
    "REBASE_META_CSV_URL = (\n",
    "    \"https://huggingface.co/datasets/rebase-energy/nve-windpower-data/resolve/main/\"\n",
    "    \"nve-windpower-metadata.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Fetchers\n",
    "# -----------------------\n",
    "def fetch_nve_in_operation(retries: int = 4, timeout: int = 60) -> list[dict]:\n",
    "    last = None\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            r = requests.get(NVE_IN_OPERATION, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if not isinstance(data, list):\n",
    "                raise ValueError(f\"Unexpected JSON type: {type(data)}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            time.sleep(2 + i * 2)\n",
    "    raise last\n",
    "\n",
    "\n",
    "def fetch_rebase_meta_csv(url: str = REBASE_META_CSV_URL, timeout: int = 120) -> pd.DataFrame:\n",
    "    r = requests.get(url, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    return pd.read_csv(io.StringIO(r.text))\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Transform\n",
    "# -----------------------\n",
    "def build_meta_enrichment(meta: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardise enrichment columns:\n",
    "      - VindkraftAnleggId (int)  [join key]\n",
    "      - lon, lat\n",
    "      - avg_hub_height, avg_rotor_diameter\n",
    "    \"\"\"\n",
    "    # Common columns in the rebase CSV:\n",
    "    # WindPowerPlantId, lat, lon, AvgHubHeight, AvgRotorDiameter\n",
    "    required = [\"WindPowerPlantId\", \"lat\", \"lon\", \"AvgHubHeight\", \"AvgRotorDiameter\"]\n",
    "    missing = [c for c in required if c not in meta.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            \"Rebase metadata CSV is missing expected columns: \"\n",
    "            f\"{missing}\\nAvailable columns: {list(meta.columns)}\"\n",
    "        )\n",
    "\n",
    "    out = meta[required].copy()\n",
    "    out = out.rename(\n",
    "        columns={\n",
    "            \"WindPowerPlantId\": \"VindkraftAnleggId\",\n",
    "            \"AvgHubHeight\": \"avg_hub_height\",\n",
    "            \"AvgRotorDiameter\": \"avg_rotor_diameter\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    out[\"VindkraftAnleggId\"] = pd.to_numeric(out[\"VindkraftAnleggId\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    for c in [\"lon\", \"lat\", \"avg_hub_height\", \"avg_rotor_diameter\"]:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "\n",
    "    return out.dropna(subset=[\"VindkraftAnleggId\"])\n",
    "\n",
    "\n",
    "def nve_to_pseudoturbines(nve_data: list[dict], enrich: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expand NVE turbine blocks into pseudo-turbines, enriched with coords + avg rotor/hub.\n",
    "\n",
    "    capacity = per-turbine MW = TurbinStorrelse_kW / 1000\n",
    "    diameter = avg_rotor_diameter (m)\n",
    "    height   = avg_hub_height (m)\n",
    "    lon/lat  = from enrich\n",
    "    manufacturer = TurbinProdusent (block-level)\n",
    "    type = onshore\n",
    "    \"\"\"\n",
    "    enrich_idx = enrich.set_index(\"VindkraftAnleggId\")\n",
    "\n",
    "    rows = []\n",
    "    for plant in nve_data:\n",
    "        pid = plant.get(\"VindkraftAnleggId\")\n",
    "        if pid is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            pid_int = int(pid)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # enrichment lookup\n",
    "        if pid_int in enrich_idx.index:\n",
    "            lon = enrich_idx.loc[pid_int, \"lon\"]\n",
    "            lat = enrich_idx.loc[pid_int, \"lat\"]\n",
    "            diameter = enrich_idx.loc[pid_int, \"avg_rotor_diameter\"]\n",
    "            height = enrich_idx.loc[pid_int, \"avg_hub_height\"]\n",
    "        else:\n",
    "            lon = lat = diameter = height = pd.NA\n",
    "\n",
    "        blocks = plant.get(\"Turbiner\") or []\n",
    "\n",
    "        # If no blocks, fall back to one plant-level row\n",
    "        if not blocks:\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"ID\": f\"NO_{pid_int}_plant\",\n",
    "                    \"capacity\": plant.get(\"InstallertEffekt_MW\"),\n",
    "                    \"diameter\": diameter,\n",
    "                    \"height\": height,\n",
    "                    \"manufacturer\": pd.NA,\n",
    "                    \"lon\": lon,\n",
    "                    \"lat\": lat,\n",
    "                    \"type\": \"onshore\",\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        for b_i, blk in enumerate(blocks):\n",
    "            n = blk.get(\"AntallTurbiner\")\n",
    "            size_kw = blk.get(\"TurbinStorrelse_kW\")\n",
    "            manu = blk.get(\"TurbinProdusent\")\n",
    "\n",
    "            cap_mw = pd.to_numeric(size_kw, errors=\"coerce\") / 1000.0 if size_kw is not None else pd.NA\n",
    "\n",
    "            # If count missing, emit one pseudo-turbine for that block\n",
    "            if n is None or int(n) <= 0:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"ID\": f\"NO_{pid_int}_blk_{b_i}_t_0\",\n",
    "                        \"capacity\": cap_mw,\n",
    "                        \"diameter\": diameter,\n",
    "                        \"height\": height,\n",
    "                        \"manufacturer\": manu if manu not in (None, \"\") else pd.NA,\n",
    "                        \"lon\": lon,\n",
    "                        \"lat\": lat,\n",
    "                        \"type\": \"onshore\",\n",
    "                    }\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            for t_i in range(int(n)):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"ID\": f\"NO_{pid_int}_blk_{b_i}_t_{t_i}\",\n",
    "                        \"capacity\": cap_mw,\n",
    "                        \"diameter\": diameter,\n",
    "                        \"height\": height,\n",
    "                        \"manufacturer\": manu if manu not in (None, \"\") else pd.NA,\n",
    "                        \"lon\": lon,\n",
    "                        \"lat\": lat,\n",
    "                        \"type\": \"onshore\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    df = pd.DataFrame(rows).reindex(columns=SCHEMA)\n",
    "    for c in [\"capacity\", \"diameter\", \"height\", \"lon\", \"lat\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def sanity(df: pd.DataFrame):\n",
    "    print(\"rows:\", len(df))\n",
    "    print(\"missing lon:\", int(df[\"lon\"].isna().sum()))\n",
    "    print(\"missing lat:\", int(df[\"lat\"].isna().sum()))\n",
    "    print(\"missing diameter:\", int(df[\"diameter\"].isna().sum()))\n",
    "    print(\"missing height:\", int(df[\"height\"].isna().sum()))\n",
    "    print(df.head(5))\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Run (notebook-safe: no sys.argv)\n",
    "# -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    out_csv = \"NO_wind_metadata_pseudoturbines.csv\"\n",
    "\n",
    "    nve = fetch_nve_in_operation()\n",
    "    meta_raw = fetch_rebase_meta_csv()\n",
    "    enrich = build_meta_enrichment(meta_raw)\n",
    "\n",
    "    df = nve_to_pseudoturbines(nve, enrich)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"Wrote {out_csv}\")\n",
    "    sanity(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd8c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9219261522588837\n",
      "count       0\n",
      "unique      0\n",
      "top       NaN\n",
      "freq      NaN\n",
      "Name: wind_offshore_MW, dtype: object\n",
      "Saved:\n",
      " - OPSD_BE_wind_hourly.csv  (50401, 3)\n",
      " - OPSD_NO_wind_hourly.csv  (50401, 3)\n",
      "\n",
      "BE head:\n",
      "                            wind_onshore_MW  wind_offshore_MW  wind_total_MW\n",
      "time                                                                       \n",
      "2014-12-31 23:00:00+00:00              NaN               NaN           0.00\n",
      "2015-01-01 00:00:00+00:00              NaN               NaN           0.00\n",
      "2015-01-01 01:00:00+00:00           216.15            518.66         734.81\n",
      "2015-01-01 02:00:00+00:00           237.18            529.46         766.64\n",
      "2015-01-01 03:00:00+00:00           326.19            406.94         733.13\n",
      "\n",
      "NO head:\n",
      "                            wind_onshore_MW wind_offshore_MW  wind_total_MW\n",
      "time                                                                      \n",
      "2014-12-31 23:00:00+00:00              NaN             <NA>           0.00\n",
      "2015-01-01 00:00:00+00:00              NaN             <NA>           0.00\n",
      "2015-01-01 01:00:00+00:00           479.40             <NA>         479.40\n",
      "2015-01-01 02:00:00+00:00           422.74             <NA>         422.74\n",
      "2015-01-01 03:00:00+00:00           408.35             <NA>         408.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hb/8jmqlr8502jd4_jj817kmrq00000gn/T/ipykernel_42236/3616409726.py:62: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  out[\"wind_total_MW\"] = out[\"wind_onshore_MW\"].fillna(0) + out[\"wind_offshore_MW\"].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "OPSD_15MIN = \"https://data.open-power-system-data.org/time_series/latest/time_series_15min_singleindex.csv\"\n",
    "OPSD_60MIN = \"https://data.open-power-system-data.org/time_series/latest/time_series_60min_singleindex.csv\"\n",
    "\n",
    "SCHEMA_COLS = [\"wind_onshore_MW\", \"wind_offshore_MW\", \"wind_total_MW\"]\n",
    "\n",
    "def load_opsd(url: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(url, index_col=0, parse_dates=True, low_memory=False)\n",
    "    df.index.name = \"time\"\n",
    "    return df\n",
    "\n",
    "def extract_wind(df: pd.DataFrame, country: str) -> pd.DataFrame:\n",
    "    # Try both OPSD naming styles\n",
    "    candidates = {\n",
    "        \"on\": [\n",
    "            f\"{country}_wind_onshore_generation_actual\",\n",
    "            f\"{country}_wind_onshore_generation\",\n",
    "        ],\n",
    "        \"off\": [\n",
    "            f\"{country}_wind_offshore_generation_actual\",\n",
    "            f\"{country}_wind_offshore_generation\",\n",
    "        ],\n",
    "        \"tot\": [\n",
    "            f\"{country}_wind_generation_actual\",\n",
    "            f\"{country}_wind_generation\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    def first_present(cols):\n",
    "        for c in cols:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    on_col = first_present(candidates[\"on\"])\n",
    "    off_col = first_present(candidates[\"off\"])\n",
    "    tot_col = first_present(candidates[\"tot\"])\n",
    "\n",
    "    # If nothing found, show hints\n",
    "    if on_col is None and off_col is None and tot_col is None:\n",
    "        hints = [c for c in df.columns if c.startswith(country + \"_wind\")]\n",
    "        raise KeyError(f\"No wind columns for {country}. Found: {hints[:40]}\")\n",
    "\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "\n",
    "    if on_col is not None:\n",
    "        out[\"wind_onshore_MW\"] = pd.to_numeric(df[on_col], errors=\"coerce\")\n",
    "    else:\n",
    "        out[\"wind_onshore_MW\"] = pd.NA\n",
    "\n",
    "    if off_col is not None:\n",
    "        out[\"wind_offshore_MW\"] = pd.to_numeric(df[off_col], errors=\"coerce\")\n",
    "    else:\n",
    "        out[\"wind_offshore_MW\"] = pd.NA\n",
    "\n",
    "    # If split exists, compute total; otherwise fall back to total column\n",
    "    if on_col is not None or off_col is not None:\n",
    "        out[\"wind_total_MW\"] = out[\"wind_onshore_MW\"].fillna(0) + out[\"wind_offshore_MW\"].fillna(0)\n",
    "    else:\n",
    "        out[\"wind_total_MW\"] = pd.to_numeric(df[tot_col], errors=\"coerce\") if tot_col is not None else pd.NA\n",
    "\n",
    "    return out[SCHEMA_COLS]\n",
    "\n",
    "def to_hourly_mean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    OPSD generation is MW averaged over the reporting interval,\n",
    "    so hourly aggregation should use mean.\n",
    "    \"\"\"\n",
    "    return df.resample(\"1H\").mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    out_be = Path(\"OPSD_BE_wind_hourly.csv\")\n",
    "    out_no = Path(\"OPSD_NO_wind_hourly.csv\")\n",
    "\n",
    "    # Belgium from 60-min\n",
    "    df_60 = load_opsd(OPSD_60MIN)\n",
    "    be = extract_wind(df_60, \"BE\")\n",
    "    be.to_csv(out_be, index=True)\n",
    "\n",
    "    no = extract_wind(df_60, \"NO\")\n",
    "    no.to_csv(out_no, index=True)\n",
    "    \n",
    "    # 1) Confirm BE offshore exists\n",
    "    print(be[\"wind_offshore_MW\"].notna().mean())\n",
    "\n",
    "    # 2) Confirm NO offshore is basically zero / missing (expected)\n",
    "    print(no[\"wind_offshore_MW\"].dropna().describe())\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    print(f\" - {out_be}  {be.shape}\")\n",
    "    print(f\" - {out_no}  {no.shape}\")\n",
    "    print(\"\\nBE head:\\n\", be.head())\n",
    "    print(\"\\nNO head:\\n\", no.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import io\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "\n",
    "# -----------------------------\n",
    "# Shared config / schema\n",
    "# -----------------------------\n",
    "SCHEMA = [\"ID\", \"capacity\", \"diameter\", \"height\", \"manufacturer\", \"lon\", \"lat\", \"type\"]\n",
    "\n",
    "# Belgium (Flanders) — Mercator OGC API Features\n",
    "BE_MERCATOR_BASE = \"https://www.mercator.vlaanderen.be/raadpleegdienstenmercatorpubliek/ogc/features/v1\"\n",
    "BE_MERCATOR_COLLECTION = \"er:er_windturb_omv\"\n",
    "\n",
    "# Belgium offshore — RBINS WFS\n",
    "BE_RBINS_WFS = \"https://spatial.naturalsciences.be/geoserver/od_nature/ows\"\n",
    "BE_RBINS_LAYER = \"od_nature:MUMM_windmill_locations_ETRS89\"\n",
    "\n",
    "# Norway — NVE operational plants (blocks)\n",
    "NO_NVE_IN_OPERATION = \"https://api.nve.no/web/WindPowerplant/GetWindPowerPlantsInOperation\"\n",
    "\n",
    "# Norway enrichment (coords + avg hub/rotor) — downloaded as CSV (no datasets/pyarrow required)\n",
    "NO_REBASE_META_CSV_URL = (\n",
    "    \"https://huggingface.co/datasets/rebase-energy/nve-windpower-data/resolve/main/\"\n",
    "    \"nve-windpower-metadata.csv\"\n",
    ")\n",
    "\n",
    "# OSM Overpass mirrors\n",
    "OVERPASS_MIRRORS = [\n",
    "    \"https://overpass.kumi.systems/api/interpreter\",\n",
    "    \"https://overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.openstreetmap.ru/api/interpreter\",\n",
    "    \"https://overpass.nchc.org.tw/api/interpreter\",\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Small helpers\n",
    "# -----------------------------\n",
    "def _to_num(x):\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return pd.NA\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        s = str(x).strip()\n",
    "        m = re.search(r\"[-+]?\\d*\\.?\\d+\", s.replace(\",\", \".\"))\n",
    "        return float(m.group(0)) if m else pd.NA\n",
    "\n",
    "\n",
    "def _ensure_lonlat_from_geometry(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    gdf = gdf.copy()\n",
    "    if gdf.crs is None:\n",
    "        gdf = gdf.set_crs(4326, allow_override=True)\n",
    "    gdf = gdf.to_crs(4326)\n",
    "    gdf[\"lon\"] = gdf.geometry.x\n",
    "    gdf[\"lat\"] = gdf.geometry.y\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def _dedup_by_distance(df: pd.DataFrame, *, km: float = 0.25, prefer_sources: Optional[list[str]] = None):\n",
    "    \"\"\"\n",
    "    Simple greedy spatial de-dup on lon/lat within 'km' radius.\n",
    "    If a 'source' column exists and prefer_sources given, higher priority kept.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    R = 6371.0\n",
    "    lat0 = math.radians(float(df[\"lat\"].dropna().mean())) if df[\"lat\"].notna().any() else 0.0\n",
    "\n",
    "    def xy(lon, lat):\n",
    "        return (math.radians(lon) * math.cos(lat0) * R, math.radians(lat) * R)\n",
    "\n",
    "    # priority ordering\n",
    "    if prefer_sources and \"source\" in df.columns:\n",
    "        pr = {s: i for i, s in enumerate(prefer_sources)}\n",
    "        df = df.copy()\n",
    "        df[\"_prio\"] = df[\"source\"].map(lambda s: pr.get(s, 9999))\n",
    "        df = df.sort_values([\"_prio\"]).drop(columns=[\"_prio\"])\n",
    "    else:\n",
    "        df = df.copy()\n",
    "\n",
    "    keep = []\n",
    "    kept_xy = []\n",
    "    km2 = km * km\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[\"lon\"]) or pd.isna(row[\"lat\"]):\n",
    "            keep.append(True)\n",
    "            continue\n",
    "        x, y = xy(float(row[\"lon\"]), float(row[\"lat\"]))\n",
    "        ok = True\n",
    "        for (kx, ky) in kept_xy:\n",
    "            dx = kx - x\n",
    "            dy = ky - y\n",
    "            if dx * dx + dy * dy <= km2:\n",
    "                ok = False\n",
    "                break\n",
    "        keep.append(ok)\n",
    "        if ok:\n",
    "            kept_xy.append((x, y))\n",
    "\n",
    "    return df.loc[keep].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def _overpass_post(query: str, *, timeout: int = 240, tries_per_mirror: int = 2):\n",
    "    last_err = None\n",
    "    for base in OVERPASS_MIRRORS:\n",
    "        for attempt in range(tries_per_mirror):\n",
    "            try:\n",
    "                r = requests.post(base, data={\"data\": query}, timeout=timeout)\n",
    "                if r.status_code == 429:\n",
    "                    time.sleep(10 + attempt * 10)\n",
    "                    continue\n",
    "                r.raise_for_status()\n",
    "                return r.json()\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                time.sleep(5 + attempt * 5)\n",
    "    raise last_err\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Belgium fetchers\n",
    "# -----------------------------\n",
    "def _fetch_be_flanders_mercator(*, timeout: int = 120) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Mercator OGC API Features collection: er:er_windturb_omv\n",
    "    \"\"\"\n",
    "    limit = 1000\n",
    "    start = 0\n",
    "    feats = []\n",
    "    while True:\n",
    "        url = f\"{BE_MERCATOR_BASE}/collections/{BE_MERCATOR_COLLECTION}/items\"\n",
    "        params = {\"f\": \"application/geo+json\", \"limit\": limit, \"startIndex\": start}\n",
    "        r = requests.get(url, params=params, timeout=timeout)\n",
    "        r.raise_for_status()\n",
    "        gj = r.json()\n",
    "        batch = gj.get(\"features\", [])\n",
    "        feats.extend(batch)\n",
    "        if len(batch) < limit:\n",
    "            break\n",
    "        start += limit\n",
    "\n",
    "    gdf = gpd.GeoDataFrame.from_features(feats, crs=\"EPSG:4326\")\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def _normalise_be_flanders(gdf: gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "    gdf = _ensure_lonlat_from_geometry(gdf)\n",
    "    # Known columns you showed:\n",
    "    # fid, ashoogte (m), rotordiameter (m), vermogenmax (kW)\n",
    "    out = pd.DataFrame({\n",
    "        \"ID\": \"BE_FLA_\" + gdf[\"fid\"].astype(str),\n",
    "        \"capacity\": pd.to_numeric(gdf.get(\"vermogenmax\"), errors=\"coerce\") / 1000.0,  # kW -> MW\n",
    "        \"diameter\": pd.to_numeric(gdf.get(\"rotordiameter\"), errors=\"coerce\"),\n",
    "        \"height\": pd.to_numeric(gdf.get(\"ashoogte\"), errors=\"coerce\"),\n",
    "        \"manufacturer\": pd.NA,\n",
    "        \"lon\": pd.to_numeric(gdf[\"lon\"], errors=\"coerce\"),\n",
    "        \"lat\": pd.to_numeric(gdf[\"lat\"], errors=\"coerce\"),\n",
    "        \"type\": \"onshore\",\n",
    "    }).reindex(columns=SCHEMA)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _fetch_be_offshore_rbines(*, timeout: int = 120) -> gpd.GeoDataFrame:\n",
    "    url = (\n",
    "        f\"{BE_RBINS_WFS}\"\n",
    "        f\"?service=WFS&version=2.0.0&request=GetFeature\"\n",
    "        f\"&typeName={BE_RBINS_LAYER}\"\n",
    "        f\"&outputFormat=application/json\"\n",
    "        f\"&srsName=EPSG:4326\"\n",
    "    )\n",
    "    return gpd.read_file(url)\n",
    "\n",
    "\n",
    "def _normalise_be_offshore(gdf: gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "    gdf = _ensure_lonlat_from_geometry(gdf)\n",
    "    # RBINS layer often has sparse attributes; make IDs from index unless something obvious exists\n",
    "    id_col = None\n",
    "    for c in [\"id\", \"ID\", \"fid\", \"FID\", \"objectid\", \"OBJECTID\", \"uuid\", \"name\", \"Naam\", \"gml_id\"]:\n",
    "        if c in gdf.columns:\n",
    "            id_col = c\n",
    "            break\n",
    "    if id_col is None:\n",
    "        ids = [\"BE_OFF_\" + str(i) for i in range(len(gdf))]\n",
    "    else:\n",
    "        ids = gdf[id_col].astype(str).tolist()\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"ID\": ids,\n",
    "        \"capacity\": pd.NA,\n",
    "        \"diameter\": pd.NA,\n",
    "        \"height\": pd.NA,\n",
    "        \"manufacturer\": pd.NA,\n",
    "        \"lon\": pd.to_numeric(gdf[\"lon\"], errors=\"coerce\"),\n",
    "        \"lat\": pd.to_numeric(gdf[\"lat\"], errors=\"coerce\"),\n",
    "        \"type\": \"offshore\",\n",
    "    }).reindex(columns=SCHEMA)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _fetch_be_onshore_osm(*, timeout: int = 240) -> gpd.GeoDataFrame:\n",
    "    template = \"\"\"\n",
    "    [out:json][timeout:180];\n",
    "    area[\"ISO3166-1\"=\"BE\"][admin_level=2]->.be;\n",
    "    (\n",
    "      {ELEMENT}(area.be)[\"power\"=\"generator\"][\"generator:source\"=\"wind\"];\n",
    "    );\n",
    "    out center tags;\n",
    "    \"\"\"\n",
    "    elements = []\n",
    "    for element in [\"node\", \"way\", \"relation\"]:\n",
    "        data = _overpass_post(template.replace(\"{ELEMENT}\", element), timeout=timeout)\n",
    "        elements.extend(data.get(\"elements\", []))\n",
    "\n",
    "    records = []\n",
    "    for el in elements:\n",
    "        tags = el.get(\"tags\", {}) or {}\n",
    "        if el[\"type\"] == \"node\":\n",
    "            lon, lat = el.get(\"lon\"), el.get(\"lat\")\n",
    "        else:\n",
    "            center = el.get(\"center\") or {}\n",
    "            lon, lat = center.get(\"lon\"), center.get(\"lat\")\n",
    "        if lon is None or lat is None:\n",
    "            continue\n",
    "        rec = {f\"tag_{k}\": v for k, v in tags.items()}\n",
    "        rec.update({\"osm_type\": el[\"type\"], \"osm_id\": el[\"id\"], \"lon\": lon, \"lat\": lat})\n",
    "        records.append(rec)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), crs=\"EPSG:4326\")\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def _normalise_be_osm(gdf: gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "    def parse_capacity_mw(x):\n",
    "        if pd.isna(x):\n",
    "            return pd.NA\n",
    "        s = str(x).strip()\n",
    "        m = re.search(r\"([-+]?\\d*\\.?\\d+)\", s.replace(\",\", \".\"))\n",
    "        if not m:\n",
    "            return pd.NA\n",
    "        val = float(m.group(1))\n",
    "        if re.search(r\"\\bMW\\b\", s, re.I):\n",
    "            return val\n",
    "        if re.search(r\"\\bkW\\b\", s, re.I):\n",
    "            return val / 1000.0\n",
    "        if re.search(r\"\\bW\\b\", s) and not re.search(r\"\\bkW\\b|\\bMW\\b\", s, re.I):\n",
    "            return val / 1e6\n",
    "        # unknown unit; assume MW-like\n",
    "        return val\n",
    "\n",
    "    def parse_m(x):\n",
    "        if pd.isna(x):\n",
    "            return pd.NA\n",
    "        s = str(x).strip()\n",
    "        m = re.search(r\"([-+]?\\d*\\.?\\d+)\", s.replace(\",\", \".\"))\n",
    "        return float(m.group(1)) if m else pd.NA\n",
    "\n",
    "    gdf = gdf.copy()\n",
    "    out = pd.DataFrame(index=gdf.index)\n",
    "    out[\"ID\"] = \"OSM_\" + gdf[\"osm_type\"].astype(str) + \"_\" + gdf[\"osm_id\"].astype(str)\n",
    "\n",
    "    cap = gdf.get(\"tag_generator:output:electricity\", pd.Series([pd.NA] * len(gdf)))\n",
    "    out[\"capacity\"] = cap.map(parse_capacity_mw)\n",
    "\n",
    "    dia = gdf.get(\"tag_rotor:diameter\", gdf.get(\"tag_rotor_diameter\", pd.Series([pd.NA] * len(gdf))))\n",
    "    out[\"diameter\"] = dia.map(parse_m)\n",
    "\n",
    "    hub = gdf.get(\"tag_hub_height\", gdf.get(\"tag_height\", pd.Series([pd.NA] * len(gdf))))\n",
    "    out[\"height\"] = hub.map(parse_m)\n",
    "\n",
    "    manu = gdf.get(\"tag_manufacturer\", gdf.get(\"tag_brand\", pd.Series([pd.NA] * len(gdf))))\n",
    "    out[\"manufacturer\"] = manu.astype(str)\n",
    "    out.loc[out[\"manufacturer\"].isin([\"nan\", \"None\", \"\"]), \"manufacturer\"] = pd.NA\n",
    "\n",
    "    out[\"lon\"] = pd.to_numeric(gdf[\"lon\"], errors=\"coerce\")\n",
    "    out[\"lat\"] = pd.to_numeric(gdf[\"lat\"], errors=\"coerce\")\n",
    "    out[\"type\"] = \"onshore\"\n",
    "\n",
    "    out = out.reindex(columns=SCHEMA)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Norway fetchers / normalisers\n",
    "# -----------------------------\n",
    "def _fetch_no_nve_operational(*, timeout: int = 60, retries: int = 4) -> list[dict]:\n",
    "    last = None\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            r = requests.get(NO_NVE_IN_OPERATION, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if not isinstance(data, list):\n",
    "                raise ValueError(f\"Unexpected JSON root type: {type(data)}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            time.sleep(2 + i * 2)\n",
    "    raise last\n",
    "\n",
    "\n",
    "def _fetch_no_enrichment_csv(*, url: str = NO_REBASE_META_CSV_URL, timeout: int = 120) -> pd.DataFrame:\n",
    "    r = requests.get(url, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    return pd.read_csv(io.StringIO(r.text))\n",
    "\n",
    "\n",
    "def _build_no_enrichment(meta: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expect (common) columns:\n",
    "      WindPowerPlantId, lat, lon, AvgHubHeight, AvgRotorDiameter\n",
    "    If upstream changes, we keep best-effort.\n",
    "    \"\"\"\n",
    "    # best-effort column picks\n",
    "    def pick(cols: Iterable[str]) -> Optional[str]:\n",
    "        for c in cols:\n",
    "            if c in meta.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    idc = pick([\"WindPowerPlantId\", \"windpowerplantid\", \"VindkraftAnleggId\", \"VindkraftanleggId\"])\n",
    "    latc = pick([\"lat\", \"Latitude\", \"latitude\"])\n",
    "    lonc = pick([\"lon\", \"Longitude\", \"longitude\"])\n",
    "    hubc = pick([\"AvgHubHeight\", \"avg_hub_height\", \"HubHeight\", \"GjsnittNavhoeyde\", \"GjsnittNavhoyde\"])\n",
    "    rotc = pick([\"AvgRotorDiameter\", \"avg_rotor_diameter\", \"RotorDiameter\", \"GjsnittRotordiameter\"])\n",
    "\n",
    "    if idc is None:\n",
    "        raise ValueError(f\"Could not find plant-id column in Norway enrichment CSV. Columns: {list(meta.columns)}\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"VindkraftAnleggId\": pd.to_numeric(meta[idc], errors=\"coerce\").astype(\"Int64\"),\n",
    "        \"lat\": pd.to_numeric(meta[latc], errors=\"coerce\") if latc else pd.NA,\n",
    "        \"lon\": pd.to_numeric(meta[lonc], errors=\"coerce\") if lonc else pd.NA,\n",
    "        \"avg_hub_height\": pd.to_numeric(meta[hubc], errors=\"coerce\") if hubc else pd.NA,\n",
    "        \"avg_rotor_diameter\": pd.to_numeric(meta[rotc], errors=\"coerce\") if rotc else pd.NA,\n",
    "    })\n",
    "    return out.dropna(subset=[\"VindkraftAnleggId\"]).drop_duplicates(subset=[\"VindkraftAnleggId\"])\n",
    "\n",
    "\n",
    "def _normalise_no_pseudoturbines(\n",
    "    nve_data: list[dict],\n",
    "    enrich: pd.DataFrame,\n",
    "    *,\n",
    "    jitter_km: float = 0.0,\n",
    "    seed: int = 0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expand turbine blocks -> pseudo-turbines at plant centroid.\n",
    "    capacity = per-turbine MW from TurbinStorrelse_kW / 1000 (if available)\n",
    "    diameter/height/lon/lat from enrichment (plant-level averages & coords)\n",
    "    manufacturer from block TurbinProdusent\n",
    "    Optionally add small spatial jitter to pseudo-turbines (for plotting / spatial joins).\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    idx = enrich.set_index(\"VindkraftAnleggId\")\n",
    "\n",
    "    rows = []\n",
    "    for plant in nve_data:\n",
    "        pid = plant.get(\"VindkraftAnleggId\")\n",
    "        if pid is None:\n",
    "            continue\n",
    "        try:\n",
    "            pid = int(pid)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        if pid in idx.index:\n",
    "            lon = idx.loc[pid, \"lon\"]\n",
    "            lat = idx.loc[pid, \"lat\"]\n",
    "            diam = idx.loc[pid, \"avg_rotor_diameter\"]\n",
    "            hub = idx.loc[pid, \"avg_hub_height\"]\n",
    "        else:\n",
    "            lon = lat = diam = hub = pd.NA\n",
    "\n",
    "        blocks = plant.get(\"Turbiner\") or []\n",
    "        if not blocks:\n",
    "            rows.append({\n",
    "                \"ID\": f\"NO_{pid}_plant\",\n",
    "                \"capacity\": _to_num(plant.get(\"InstallertEffekt_MW\")),\n",
    "                \"diameter\": _to_num(diam),\n",
    "                \"height\": _to_num(hub),\n",
    "                \"manufacturer\": pd.NA,\n",
    "                \"lon\": _to_num(lon),\n",
    "                \"lat\": _to_num(lat),\n",
    "                \"type\": \"onshore\",\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        for b_i, blk in enumerate(blocks):\n",
    "            n = blk.get(\"AntallTurbiner\")\n",
    "            try:\n",
    "                n = int(n) if n is not None else 0\n",
    "            except Exception:\n",
    "                n = 0\n",
    "\n",
    "            size_kw = blk.get(\"TurbinStorrelse_kW\")\n",
    "            cap_mw = pd.to_numeric(size_kw, errors=\"coerce\") / 1000.0 if size_kw is not None else pd.NA\n",
    "            manu = blk.get(\"TurbinProdusent\")\n",
    "            manu = manu if manu not in (None, \"\") else pd.NA\n",
    "\n",
    "            if n <= 0:\n",
    "                n = 1  # at least one pseudo-turbine for the block\n",
    "\n",
    "            # jitter: uniform in circle radius jitter_km\n",
    "            for t_i in range(n):\n",
    "                jl = _to_num(lon)\n",
    "                jt = _to_num(lat)\n",
    "                if jitter_km and (jl is not pd.NA) and (jt is not pd.NA):\n",
    "                    # crude jitter in degrees (OK for small distances)\n",
    "                    # 1 deg lat ~ 111 km; lon scales by cos(lat)\n",
    "                    r = jitter_km * math.sqrt(rng.random())\n",
    "                    ang = 2 * math.pi * rng.random()\n",
    "                    dlat = (r * math.sin(ang)) / 111.0\n",
    "                    dlon = (r * math.cos(ang)) / (111.0 * max(0.2, math.cos(math.radians(float(jt)))))\n",
    "                    jl = float(jl) + dlon\n",
    "                    jt = float(jt) + dlat\n",
    "\n",
    "                rows.append({\n",
    "                    \"ID\": f\"NO_{pid}_blk_{b_i}_t_{t_i}\",\n",
    "                    \"capacity\": cap_mw,\n",
    "                    \"diameter\": _to_num(diam),\n",
    "                    \"height\": _to_num(hub),\n",
    "                    \"manufacturer\": manu,\n",
    "                    \"lon\": jl,\n",
    "                    \"lat\": jt,\n",
    "                    \"type\": \"onshore\",\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows).reindex(columns=SCHEMA)\n",
    "    for c in [\"capacity\", \"diameter\", \"height\", \"lon\", \"lat\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# PUBLIC FUNCTIONS YOU ASKED FOR\n",
    "# -----------------------------\n",
    "def create_turbine_metadata_be(\n",
    "    *,\n",
    "    include_osm_wallonia_brussels: bool = True,\n",
    "    dedup_km: float = 0.25,\n",
    "    timeout: int = 120,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build Belgium turbine metadata (onshore + offshore) into one DataFrame with SCHEMA.\n",
    "    Sources:\n",
    "      - Flanders (onshore): Mercator OGC API (rich specs)\n",
    "      - Offshore: RBINS WFS points\n",
    "      - Wallonia+Brussels (onshore, best-effort): OSM Overpass (mirrors + retries)\n",
    "\n",
    "    Returns: DataFrame with columns SCHEMA.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "\n",
    "    # Offshore (RBINS)\n",
    "    be_off_gdf = _fetch_be_offshore_rbines(timeout=timeout)\n",
    "    be_off = _normalise_be_offshore(be_off_gdf)\n",
    "    be_off[\"source\"] = \"RBINS\"\n",
    "    parts.append(be_off)\n",
    "\n",
    "    # Flanders onshore (Mercator)\n",
    "    be_fla_gdf = _fetch_be_flanders_mercator(timeout=timeout)\n",
    "    be_fla = _normalise_be_flanders(be_fla_gdf)\n",
    "    be_fla[\"source\"] = \"MERCATOR\"\n",
    "    parts.append(be_fla)\n",
    "\n",
    "    # Wallonia+Brussels onshore (OSM)\n",
    "    if include_osm_wallonia_brussels:\n",
    "        be_osm_gdf = _fetch_be_onshore_osm(timeout=max(timeout, 180))\n",
    "        be_osm = _normalise_be_osm(be_osm_gdf)\n",
    "        be_osm[\"source\"] = \"OSM\"\n",
    "        parts.append(be_osm)\n",
    "\n",
    "    be = pd.concat(parts, ignore_index=True, sort=False)\n",
    "\n",
    "    # Prefer authoritative sources if duplicates\n",
    "    be = _dedup_by_distance(be, km=dedup_km, prefer_sources=[\"RBINS\", \"MERCATOR\", \"OSM\"])\n",
    "\n",
    "    # Ensure schema only\n",
    "    be = be.reindex(columns=SCHEMA)\n",
    "    return be\n",
    "\n",
    "\n",
    "def create_turbine_metadata_no(\n",
    "    *,\n",
    "    jitter_km: float = 0.0,\n",
    "    seed: int = 0,\n",
    "    timeout: int = 120,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build Norway pseudo-turbine metadata (onshore) into SCHEMA.\n",
    "    Sources:\n",
    "      - NVE operational API: turbine blocks (count, size, manufacturer)\n",
    "      - Enrichment CSV: plant lon/lat + avg hub height + avg rotor diameter (best-effort)\n",
    "\n",
    "    Parameters:\n",
    "      jitter_km: if >0, spatially jitter pseudo-turbines around plant centroid (useful for maps).\n",
    "    \"\"\"\n",
    "    nve = _fetch_no_nve_operational(timeout=min(timeout, 120))\n",
    "    meta_raw = _fetch_no_enrichment_csv(timeout=timeout)\n",
    "    enrich = _build_no_enrichment(meta_raw)\n",
    "\n",
    "    no = _normalise_no_pseudoturbines(nve, enrich, jitter_km=jitter_km, seed=seed)\n",
    "    return no\n",
    "\n",
    "def clean_and_impute_turbine_metadata(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    country: str,\n",
    "    drop_if_no_capacity: bool = True,\n",
    "    verbose: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans turbine metadata by:\n",
    "    - imputing missing capacity / diameter / height\n",
    "    - converting capacity from MW -> kW (FINAL OUTPUT)\n",
    "    - optionally dropping rows still missing capacity\n",
    "\n",
    "    Assumes INPUT capacity is in MW.\n",
    "    Works for BE and NO outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 0) Enforce numeric + clarify units (MW internally)\n",
    "    # -------------------------------------------------\n",
    "    df[\"capacity\"] = pd.to_numeric(df[\"capacity\"], errors=\"coerce\")  # MW\n",
    "    df[\"diameter\"] = pd.to_numeric(df.get(\"diameter\"), errors=\"coerce\")\n",
    "    df[\"height\"] = pd.to_numeric(df.get(\"height\"), errors=\"coerce\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 1) Capacity imputation (MW)\n",
    "    # -----------------------\n",
    "    if df[\"capacity\"].isna().any():\n",
    "        medians = (\n",
    "            df.groupby(\"type\")[\"capacity\"]\n",
    "            .median()\n",
    "            .dropna()\n",
    "        )\n",
    "\n",
    "        def fill_capacity(row):\n",
    "            if not pd.isna(row[\"capacity\"]):\n",
    "                return row[\"capacity\"]\n",
    "            return medians.get(row[\"type\"], np.nan)\n",
    "\n",
    "        df[\"capacity\"] = df.apply(fill_capacity, axis=1)\n",
    "\n",
    "    # -----------------------\n",
    "    # 2) Diameter imputation\n",
    "    # -----------------------\n",
    "    # Empirical scaling: D ≈ 35 * sqrt(P_MW)\n",
    "    mask_d = df[\"diameter\"].isna() & df[\"capacity\"].notna()\n",
    "    df.loc[mask_d, \"diameter\"] = (\n",
    "        35.0 * np.sqrt(df.loc[mask_d, \"capacity\"])\n",
    "    )\n",
    "\n",
    "    # Clamp to realistic bounds\n",
    "    df[\"diameter\"] = df[\"diameter\"].clip(lower=40, upper=260)\n",
    "\n",
    "    # -----------------------\n",
    "    # 3) Hub height imputation\n",
    "    # -----------------------\n",
    "    mask_h = df[\"height\"].isna() & df[\"diameter\"].notna()\n",
    "\n",
    "    df.loc[mask_h & (df[\"type\"] == \"onshore\"), \"height\"] = (\n",
    "        1.1 * df.loc[mask_h & (df[\"type\"] == \"onshore\"), \"diameter\"]\n",
    "    )\n",
    "\n",
    "    df.loc[mask_h & (df[\"type\"] == \"offshore\"), \"height\"] = (\n",
    "        0.9 * df.loc[mask_h & (df[\"type\"] == \"offshore\"), \"diameter\"]\n",
    "    )\n",
    "\n",
    "    # -----------------------\n",
    "    # 4) Final drop (MW stage)\n",
    "    # -----------------------\n",
    "    if drop_if_no_capacity:\n",
    "        before = len(df)\n",
    "        df = df.dropna(subset=[\"capacity\"])\n",
    "        after = len(df)\n",
    "        if verbose and before != after:\n",
    "            print(f\"[{country}] Dropped {before-after} rows with no capacity\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 5) Convert capacity MW → kW (FINAL OUTPUT)\n",
    "    # -----------------------\n",
    "    df[\"capacity\"] = df[\"capacity\"] * 1000.0  # MW → kW\n",
    "\n",
    "    # -----------------------\n",
    "    # 6) Sanity report\n",
    "    # -----------------------\n",
    "    if verbose:\n",
    "        print(f\"[{country}] Final turbine metadata (capacity in kW):\")\n",
    "        print(\" rows:\", len(df))\n",
    "        print(\" missing capacity:\", int(df[\"capacity\"].isna().sum()))\n",
    "        print(\" missing diameter:\", int(df[\"diameter\"].isna().sum()))\n",
    "        print(\" missing height:\", int(df[\"height\"].isna().sum()))\n",
    "        print(\n",
    "            \" capacity range [MW]:\",\n",
    "            (df[\"capacity\"] / 1000).min(),\n",
    "            \"–\",\n",
    "            (df[\"capacity\"] / 1000).max(),\n",
    "        )\n",
    "\n",
    "    return df\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    be = create_turbine_metadata_be(include_osm_wallonia_brussels=True, dedup_km=0.25)\n",
    "    be = clean_and_impute_turbine_metadata(be, country=\"BE\")\n",
    "    be.to_csv(\"BE_turbine_metadata.csv\", index=False)\n",
    "    print(\"BE saved:\", be.shape)\n",
    "\n",
    "    no = create_turbine_metadata_no(jitter_km=0.0, seed=0)\n",
    "    no = clean_and_impute_turbine_metadata(no, country=\"NO\")\n",
    "    no.to_csv(\"NO_turbine_metadata.csv\", index=False)\n",
    "    print(\"NO saved:\", no.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230b6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb552b82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m be = create_turbine_metadata_be()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m be = \u001b[43mclean_and_impute_turbine_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcountry\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m no = create_turbine_metadata_no()\n\u001b[32m      5\u001b[39m no = clean_and_impute_turbine_metadata(no, country=\u001b[33m\"\u001b[39m\u001b[33mNO\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mclean_and_impute_turbine_metadata\u001b[39m\u001b[34m(df, country, drop_if_no_capacity, verbose)\u001b[39m\n\u001b[32m     39\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m row[\u001b[33m\"\u001b[39m\u001b[33mcapacity\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m medians.get(row[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m], np.nan)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mcapacity\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfill_capacity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# 2) Diameter imputation\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Empirical scaling: D ≈ 35 * sqrt(P_MW)\u001b[39;00m\n\u001b[32m     48\u001b[39m mask_d = df[\u001b[33m\"\u001b[39m\u001b[33mdiameter\u001b[39m\u001b[33m\"\u001b[39m].isna() & df[\u001b[33m\"\u001b[39m\u001b[33mcapacity\u001b[39m\u001b[33m\"\u001b[39m].notna()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pyvwf/lib/python3.12/site-packages/pandas/core/frame.py:10401\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10387\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10389\u001b[39m op = frame_apply(\n\u001b[32m  10390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10391\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10399\u001b[39m     kwargs=kwargs,\n\u001b[32m  10400\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10401\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pyvwf/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pyvwf/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/pyvwf/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mclean_and_impute_turbine_metadata.<locals>.fill_capacity\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd.isna(row[\u001b[33m\"\u001b[39m\u001b[33mcapacity\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m row[\u001b[33m\"\u001b[39m\u001b[33mcapacity\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m medians.get(row[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m], \u001b[43mnp\u001b[49m.nan)\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "be = create_turbine_metadata_be()\n",
    "be = clean_and_impute_turbine_metadata(be, country=\"BE\")\n",
    "\n",
    "no = create_turbine_metadata_no()\n",
    "no = clean_and_impute_turbine_metadata(no, country=\"NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "no.to_csv(\"no_md.csv\", index=False)\n",
    "be.to_csv(\"be_md.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f3eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvwf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
